== function is an object ==

Start off by showing that a python function is an object.
Must be comfortable with the idea that a function can be passed
as an argument, e.g.

def sum(x, y):
    return x+y

a = sum

print( a(5,5) )

def call_me(function, arg1, arg2):
    return function(arg1, arg2)

call_me( sum, 5, 5 )

Can then go off showing map and reduce

== map ==

a = [1,2,3,4]
b = [5,6,7,8]

def sum(a, b):
    return a+b

result = []

for i in range(0,4):
    result.append( sum(a[i],b[i]) )

result = map(sum, a, b)

All map does is call 'function' on each item in the list in turn,
saving the answers back to an array.

files = sys.argv[1:]

def countLines(filename):
    lines = open(filename, "r").readlines()
    return len(lines)

result = map(countLines, files)

== reduce ==

result is an array

[2,4,6,8]

def sum(a, b):
    return a+b

total = reduce(sum, result)

nlines = reduce( sum, map(countLines, files) )

== lambda ==

Anonymous function - just used when we want to write a small
function but don't want to give the name

def f(x):
    return x**2

g = f

g = lambda x: x**2

g(2)
f(2)

nlines = reduce( lambda x,y: x+y, map(countLines, files) )

Also use lambda to bind arguments to fixed values

e.g.

add_five = lambda x: sum(x,5)

print( add_five(1) )

== closures (inner functions) - move to epilogue - closures ==

def add(x,y):
    return x+y

def add(x):
    def inner(y):
        return x+y
    return inner

plus_5 = add(5)
plus_6 = add(6)

plus_5(1)
plus_6(1)

def add(x):
    return lambda y: x+y

== multiprocessing ==

multiprocessing.pool()

multiprocessing.cpu_count()

importance of if __name__ == "__main__": etc.

pool stuff

zip two arrays together

== have a subsection to go deeper into zip and iterators (optional)
    - iterator, itertools.izip, then generators

Run function in parallel across the array

== multiprocess queue ==

Queue used to pass information to members of the pool

== multiprocess background process ==

Process object

== cluster - scoop ==

First, scoop.future.map - same as map

Then, how to run on a cluster.

Then scoop.mapReduce

Then scoop.execute with Future

== cluster - Futures ==

scoop.submit returns a Future

result not ready yet. Holder for a future result.

Future exists in Python >=3.2, can use for multithreading job

concurrent.Futures.ProcessPoolExecuter()

== Epilogue - Inner functions and closures ==

Copy from above

== Epilogue - Decorators ==

Inner functions

Decorators

== Epilogue - Iterators and Generators ==

Itertools.izip, iterators and generators

== What next? ==

Python MPI, e.g. via SciPy or PyMPI4. Link to their 
tutorials, and to my MPI workshop

Parallel Python WIKI to show all of the parallel frameworks.
PyOpenCL to parallelise using OpenCL (multicore and GPUs)
