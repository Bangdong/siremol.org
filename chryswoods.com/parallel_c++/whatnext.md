# What next?

You have now seen how you can write efficient parallel C++ programs by expressing your algorithm in terms of collective operations, like map/reduce.

You have also now been introduced to 
[Intel's Threading Building Blocks (TBB)](https://www.threadingbuildingblocks.org)
which provide a free, portable and high-level framework for writing efficient task-based parallel programs. You have learned enough of TBB to see how to write a parallel implementation of map/reduce.

If you would like to learn more about TBB, then please check out the
[documentation on the website](https://www.threadingbuildingblocks.org/docs/help/index.htm), or the much more useful book, 
[Intel Threading Building Blocks, by James Reinders](https://www.amazon.co.uk/Intel-Threading-Building-Blocks-Parallelism/dp/0596514808/ref=sr_1_1?ie=UTF8&qid=1471430425&sr=8-1&keywords=threading+building+blocks).

The concepts of map/reduce are common to other parallel programming libraries and languages. You can learn how to write map/reduce using OpenMP in [my OpenMP course](../beginning_openmp), and to write it in MPI using [my MPI course](../beginning_mpi). There are parallel map/reduce libraries available in Python, which are described in my [parallel python](../parallel_python) course.

***

# [Previous](parallel_mapreduce.md) [Up](README.md) [Next](README.md)
